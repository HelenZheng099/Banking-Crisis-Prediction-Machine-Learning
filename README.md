## Communication

There are 62 missing values in variables `iso2`, 215 missing values in `Banking Crisis`, and more than 9000 each in the `variablessi01-07`,`sm01`,`oi01-02`. It seems that most of the missing values in the variabless`i01-07`,`sm01`, and `oi01-02` come from before 2000 and after 2020. Missing values in the label `Banking Crisis` come from year 2015-2016, and two countries: Ireland and Switzerland. The iso2 of Namibia, which is 'NA', was also wrongly recognized as missing value.

I drop the missing values in the label `Banking Crisis`, and fill in the missing value in `iso2`. Regarding the other varriables, I choose KNN imputation to address the missing values because KNN imputation is based on the principle of similarity. It assumes neighboring samples have similar feature values and can largely preserve the intrinsic relationships between sample.

Box plots indicate that outliers are predominantly concentrated at higher values. For instance, `si02`, `si04` ,`si07`, `si05` and `oi02` exhibit many high-end outliers. In contrast, `si05` have fewer outliers at the lower end. According to the Box plots, I chose limits=[0.02,0.1] for scipy.stats. mstats.winsorize function, meaning trimming the lowest 2% and highest 10% of the data points. After trimming, the outliers are removed from the dataframe.

In the feature engineering part, for the current scenario, encoding region and income with OneHotEncoder is chosen because these features are unordered, and I want to retain the information in these features without introducing potential assumptions of order. I think this is helpful for most tree-based models and linear models, as they do not inherently interpret mathematical operations between categories.

I also removed 'country' and 'year' from model training data. It is under the consideration of generalization and interpretability. These fields can increase noise and limit the model's ability to apply learned patterns to new, unseen data. One-hot encoding 'country' inflates the number of features, complicating training and adding minimal information. Predictions also become less understandable when tied to specific countries or years rather than broader trends or indicators.

The primary metric chosen is ROC-AUC score, because it considers both the sensitivity of the model (recall) and the specificity (the ability to correctly identify non-crisis situations). XGBoost is selected as the model due to its superior performance in metrics and its ability to mitigate overfitting. For the cross-validation method, taking into account time continuity and potential trend changes, I chose TimeSeriesSplit to assess the average performance metrics of the model across different time periods.

When analyzing financial and macroeconomic data that related to time series analysis, changes in variables are important. Rates of change may include more valuable information than absolute values, as they reflect dynamic shifts in economic indicators. The deterioration of the asset quality and the excessive exposure to risky assets, along with low bank liquidity, were strongly related to both the 2007-2008 Global Financial Crisis and the 2010-2012 European Debt Crisis. A positive value in the change rate may happend before the Banking Crisis. I added the percentage change of the following variables `si03`, `si04` ,`si05`, `si06` and `oi02`. After adding these new variables, the AUC score enhanced by 0.06, F1 and accuracy enhanced by 0.18 and 0.22.

Based on the data coverage analysis, the period from 2000 to 2014 appears to have the fewest missing values. However, it is important to take the occurrence of some important crisis such as the Latin American debt crisis of the 1980s and the Asian Crisis of 1997 into consideration for the time spans. Therefore, in the model building phase, I controlled the time period selection. Initially, I tried the time span from 2000 to 2014, which achieved an AUC score of 0.684 and a recall of 0.451. I also experimented with the time spans of 1995-2014 and 1980-2024, but both showed weaker performance with an AUC score of 0.680 and 0.592.

There is a significant imbalance issue in the labels, with 772 instances labeled as '0' and 130 instances labeled as '1'. As an initial attempt to address the imbalance issue, I first removed 400 instances with a label of '0'. However, this resulted in poor performance, with an AUC of only 0.676. Therefore, alternative approaches for generating new data points are being explored. In the second attempt, I introduced SMOTE (Synthetic Minority Class Oversampling) on the training data, which achieved an 0.08 increase in AUC and 0.36 incease in accuracy.

Consequently, the model utilized a sample ranging from 2014 to 2020, incorporating cross-validation and SMOTE techniques, excluding the sample related to year and country name, as well as including five other variables representing percentage changes: `si03_change`, `si04_change`, `si05_change`, `si06_change`, and `oi02_change`. In the test dataset, there were 11 samples labeled as '1', of which the model successfully predicted 10. However, it misclassified two samples labeled as '0' as '1', which are Australia and Finland, and it failed to correctly predict one sample, which is England.

Based on the explanation of the Shapley value, the top 5 factors that may have contributed to the banking crisis are `si02`, `sm01`, `region_European & Central Asian`,`oi02`, `si07`. Among these factors, `si02` and `sm01` have the strongest correlation with the banking crisis, followed by `region_European & Central Asian`,`oi02`, and `si07`. This implies that countries facing high stock price volatility, significant nonperforming loans, a high ratio of bank deposits to GDP, and particularly those located in the European & Central Asian region are more likely to experience a banking crisis.

In a more comprehensive model, I think it's important to take this time series effect into account when building the machine learning model. Some indicator,such as Bank deposits to GDP (%),Bank regulatory capital to risk-weighted assets (%), may peak before the Banking cirsis and be treated as an leading indicator, while some indicator may reveal lagging effect in predicting the Banking cirsis. One can observe the fluctuations of these indicators before and after banking crises using a sliding window, and then analyze the temporal relationship between the indicators and banking crises using ACF and PACF. If the data exhibits strong time series characteristics, one may also try LSTM networks or other types of RNNs.
